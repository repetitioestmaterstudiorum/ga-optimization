{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR ANN Optimization using a Genetic Algorith vs Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pt_fc_layers_viz import draw_pt_fc_layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_device():\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\" # Apple M1\n",
    "\n",
    "    print(f\"We are using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED = np.random.randint(0, 1000)\n",
    "RANDOM_SEED = 13\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, *, layers=[2, 2, 1], activation_fn=nn.LeakyReLU, requires_grad=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add each layer followed by the activation function\n",
    "        module_list = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            module_list.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            if activation_fn is not None:\n",
    "                module_list.append(activation_fn())\n",
    "        if activation_fn is not None:\n",
    "            module_list.pop() # The last layer should not have an activation function\n",
    "\n",
    "        self.layers = nn.ModuleList(module_list)\n",
    "\n",
    "        if requires_grad is False:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.Tensor([[0], [1], [1], [0]])\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_parameters_as_vector(model: nn.Module) -> torch.Tensor:\n",
    "    return torch.cat([p.flatten() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_parameters_from_vector(model: nn.Module, param_vector: torch.Tensor) -> nn.Module:\n",
    "    position = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements = param.numel()\n",
    "        values_slice = param_vector[position:position+num_elements]\n",
    "        param.data.copy_(values_slice.view(param.shape)) # A.copy_(B) copies B values into A\n",
    "        position += num_elements\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = ANN(layers=[2, 2, 1])\n",
    "model_1 = ANN(layers=[2, 2, 1])\n",
    "set_all_parameters_from_vector(model_1, get_all_parameters_as_vector(model_0))\n",
    "assert get_all_parameters_as_vector(model_0).equal(get_all_parameters_as_vector(model_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popultation Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be optimized by using torch internals to initialize parameters instead of creating lots of models.\n",
    "\n",
    "def get_population_he(model: nn.Module, size: int) -> torch.Tensor:\n",
    "    layers = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layers.append(layer.in_features)\n",
    "    layers = layers + [model.layers[-1].out_features]\n",
    "\n",
    "    activation_fn = type(model.layers[1])\n",
    "    \n",
    "    param_pop = []\n",
    "    for _ in range(size):\n",
    "        model = ANN(layers=layers, activation_fn=activation_fn)\n",
    "        \n",
    "        params = get_all_parameters_as_vector(model)\n",
    "        param_pop.append(params)\n",
    "\n",
    "    return torch.stack(param_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random parameters in the range init_range\n",
    "\n",
    "# def get_population(model: nn.Module, size: int) -> torch.Tensor:\n",
    "#     original_params = get_all_parameters_as_vector(model)\n",
    "#     n_params = original_params.numel()\n",
    "    \n",
    "#     param_sets = []\n",
    "#     for _ in range(size):\n",
    "#         new_params = (torch.rand(n_params) * 2) - 1\n",
    "#         param_sets.append(new_params)\n",
    "\n",
    "#     return torch.stack(param_sets)\n",
    "\n",
    "# In-place version\n",
    "def get_population(model: nn.Module, size: int, init_range=.5) -> torch.Tensor:\n",
    "    original_params = get_all_parameters_as_vector(model)\n",
    "    n_params = original_params.numel()\n",
    "    \n",
    "    param_pop = torch.empty(size, n_params)\n",
    "    \n",
    "    for i in range(size):\n",
    "        param_pop[i].uniform_(-init_range, init_range)\n",
    "\n",
    "    return param_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(population: torch.Tensor, model: nn.Module, loss_fn: nn.Module, X: torch.Tensor, Y: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    losses = []\n",
    "    for individual in population:\n",
    "        model = set_all_parameters_from_vector(model, individual)\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, Y).mean().item()\n",
    "        losses.append(loss)\n",
    "\n",
    "    losses = torch.Tensor(losses)\n",
    "    _, ranks = torch.sort(torch.argsort(losses, descending=True)) # argsort sorts the losses descending, then sort sorts the indices of the argsort\n",
    "    \n",
    "    return losses, ranks # A high rank means a low loss. population[ranks[0]] is the best individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_rank_selection(population: torch.Tensor, percentage: float, ranks: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    n_selected = int(percentage * population.shape[0])\n",
    "    \n",
    "    # P(i) = (1 - e ^ -i) / c\n",
    "    # i is the fitness rank and c is a normalization constant according to the population size\n",
    "    probabilities_without_norm = 1 - torch.exp(-ranks)\n",
    "    c = probabilities_without_norm.sum()\n",
    "    selection_probabilities = probabilities_without_norm / c \n",
    "\n",
    "    selected_indices = torch.multinomial(selection_probabilities, n_selected, replacement=True) # replacement=True means that the same index can be selected multiple times\n",
    "    \n",
    "    selected_individuals = population[selected_indices]\n",
    "    return selected_individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(population: torch.Tensor, percentage: float, ranks: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    selection_probabilities = ranks / ranks.sum()\n",
    "    n_selected = int(percentage * population.shape[0])\n",
    "    \n",
    "    selected_indices = torch.multinomial(selection_probabilities, n_selected, replacement=True)\n",
    "    \n",
    "    selected_individuals = population[selected_indices]\n",
    "    return selected_individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cross(individuals: torch.Tensor, n_offspring: int) -> torch.Tensor:\n",
    "    parent_1_indices = torch.randint(individuals.shape[0], size=(n_offspring,))\n",
    "    parent_2_indices = torch.randint(individuals.shape[0], size=(n_offspring,))\n",
    "    \n",
    "    parent_1 = individuals[parent_1_indices]\n",
    "    parent_2 = individuals[parent_2_indices]\n",
    "    \n",
    "    offspring = parent_1.add_(parent_2).div_(2) # Like `(parent_1 + parent_2) / 2` but in-place (faster)\n",
    "\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_point_cross(individuals: torch.Tensor, n_offspring: int) -> torch.Tensor:\n",
    "    parent_1_indices = torch.randint(individuals.shape[0], size=(n_offspring,))\n",
    "    parent_2_indices = torch.randint(individuals.shape[0], size=(n_offspring,))\n",
    "    \n",
    "    parent_1 = individuals[parent_1_indices]\n",
    "    parent_2 = individuals[parent_2_indices]\n",
    "    \n",
    "    crossover_point = torch.randint(individuals.shape[1], size=(1,)).item()\n",
    "\n",
    "    offspring = torch.cat((parent_1[:, :crossover_point], parent_2[:, crossover_point:]), dim=1)\n",
    "\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mutate_population(population: torch.Tensor, mutation_rate: float, mutation_range=0.5) -> torch.Tensor:\n",
    "#     total_cells = population.numel()\n",
    "#     n_mutations = int(mutation_rate * total_cells)\n",
    "#     print(f\"Mutating {n_mutations} cells out of {total_cells}\")\n",
    "\n",
    "#     cell_indices = torch.randperm(total_cells)[:n_mutations]\n",
    "\n",
    "#     for index in cell_indices:\n",
    "#         row = index // population.shape[1]\n",
    "#         col = index % population.shape[1]\n",
    "#         population[row, col].uniform_(-mutation_range, mutation_range)\n",
    "    \n",
    "#     return population\n",
    "\n",
    "# Optimized version: no for loop, no random permutation, rows and cols are calculated in one go\n",
    "def mutate_population(population: torch.Tensor, mutation_rate: float, mutation_range=0.5) -> torch.Tensor:\n",
    "    total_cells = population.numel()\n",
    "    n_mutations = int(mutation_rate * total_cells)\n",
    "\n",
    "    cell_indices = torch.randint(0, total_cells, (n_mutations,), dtype=torch.long)\n",
    "\n",
    "    rows = cell_indices // population.shape[1]\n",
    "    cols = cell_indices % population.shape[1]\n",
    "\n",
    "    mutations = torch.rand(n_mutations).uniform_(-mutation_range, mutation_range)\n",
    "    population[rows, cols] += mutations\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.3, Par mut rate: 0.03, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.762318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is below 0.076232, reducing mutation range to 0.150000(p) and 0.090000(o)\n",
      "Loss is below 0.007189, reducing mutation range to 0.045000(p) and 0.027000(o)\n",
      "Loss is below 0.000710, reducing mutation range to 0.013500(p) and 0.008100(o)\n",
      "Loss is below 0.000066, reducing mutation range to 0.004050(p) and 0.002430(o)\n",
      "Epoch 176: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 176: 0.000010, time: 17.84s, goodness: 0.03\n",
      "Trial 2: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.3, Par mut rate: 0.05, Cross method: one_point, Cross size: 100, Off mut range: 0.6, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.742514\n",
      "Loss is below 0.074251, reducing mutation range to 0.240000(p) and 0.120000(o)\n",
      "Loss is below 0.007240, reducing mutation range to 0.096000(p) and 0.048000(o)\n",
      "Loss is below 0.000656, reducing mutation range to 0.038400(p) and 0.019200(o)\n",
      "Loss is below 0.000063, reducing mutation range to 0.015360(p) and 0.007680(o)\n",
      "Final loss in epoch 200: 0.000015, time: 16.42s, goodness: 0.05\n",
      "Trial 3: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.743684\n",
      "Final loss in epoch 200: 0.126026, time: 18.85s, goodness: 475.15\n",
      "Trial 4: Population initialized with method random (initializaiton range +/-1.1)\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 200, Off mut range: 0.6, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 1.266429\n",
      "Loss is below 0.126643, reducing mutation range to 0.240000(p) and 0.240000(o)\n",
      "Loss is below 0.012145, reducing mutation range to 0.096000(p) and 0.096000(o)\n",
      "Loss is below 0.001193, reducing mutation range to 0.038400(p) and 0.038400(o)\n",
      "Loss is below 0.000110, reducing mutation range to 0.015360(p) and 0.015360(o)\n",
      "Loss is below 0.000010, reducing mutation range to 0.006144(p) and 0.006144(o)\n",
      "Epoch 113: Loss is below 1e-05: 0.000007, stopping training\n",
      "Final loss in epoch 113: 0.000007, time: 11.88s, goodness: 0.01\n",
      "Trial 5: Population initialized with method he\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.740357\n",
      "Final loss in epoch 200: 0.125980, time: 21.65s, goodness: 545.50\n",
      "Trial 6: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.741427\n",
      "Loss is below 0.074143, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007407, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000690, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Final loss in epoch 200: 0.000101, time: 18.00s, goodness: 0.36\n",
      "Trial 7: Population initialized with method random (initializaiton range +/-0.7)\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.2, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.745001\n",
      "Loss is below 0.074500, reducing mutation range to 0.200000(p) and 0.080000(o)\n",
      "Loss is below 0.007083, reducing mutation range to 0.080000(p) and 0.032000(o)\n",
      "Loss is below 0.000708, reducing mutation range to 0.032000(p) and 0.012800(o)\n",
      "Loss is below 0.000064, reducing mutation range to 0.012800(p) and 0.005120(o)\n",
      "Epoch 155: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 155: 0.000010, time: 14.29s, goodness: 0.02\n",
      "Trial 8: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.712464\n",
      "Loss is below 0.071246, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.007087, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000694, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000063, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 110: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 110: 0.000009, time: 9.69s, goodness: 0.01\n",
      "Trial 9: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.826483\n",
      "Loss is below 0.082648, reducing mutation range to 0.150000(p) and 0.120000(o)\n",
      "Loss is below 0.007541, reducing mutation range to 0.045000(p) and 0.036000(o)\n",
      "Loss is below 0.000701, reducing mutation range to 0.013500(p) and 0.010800(o)\n",
      "Loss is below 0.000070, reducing mutation range to 0.004050(p) and 0.003240(o)\n",
      "Epoch 109: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 109: 0.000009, time: 9.22s, goodness: 0.01\n",
      "Trial 10: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.827825\n",
      "Loss is below 0.082782, reducing mutation range to 0.150000(p) and 0.150000(o)\n",
      "Loss is below 0.008258, reducing mutation range to 0.045000(p) and 0.045000(o)\n",
      "Loss is below 0.000742, reducing mutation range to 0.013500(p) and 0.013500(o)\n",
      "Loss is below 0.000070, reducing mutation range to 0.004050(p) and 0.004050(o)\n",
      "Epoch 139: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 139: 0.000009, time: 13.96s, goodness: 0.02\n",
      "Trial 11: Population initialized with method random (initializaiton range +/-0.8999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.936038\n",
      "Loss is below 0.093604, reducing mutation range to 0.180000(p) and 0.120000(o)\n",
      "Loss is below 0.009125, reducing mutation range to 0.054000(p) and 0.036000(o)\n",
      "Loss is below 0.000891, reducing mutation range to 0.016200(p) and 0.010800(o)\n",
      "Loss is below 0.000067, reducing mutation range to 0.004860(p) and 0.003240(o)\n",
      "Epoch 64: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 64: 0.000009, time: 5.80s, goodness: 0.00\n",
      "Trial 12: Population initialized with method random (initializaiton range +/-0.8999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.911156\n",
      "Loss is below 0.091116, reducing mutation range to 0.180000(p) and 0.120000(o)\n",
      "Loss is below 0.008760, reducing mutation range to 0.054000(p) and 0.036000(o)\n",
      "Loss is below 0.000840, reducing mutation range to 0.016200(p) and 0.010800(o)\n",
      "Loss is below 0.000081, reducing mutation range to 0.004860(p) and 0.003240(o)\n",
      "Epoch 174: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 174: 0.000010, time: 15.65s, goodness: 0.03\n",
      "Trial 13: Population initialized with method random (initializaiton range +/-0.8999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.3, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.939780\n",
      "Loss is below 0.093978, reducing mutation range to 0.180000(p) and 0.090000(o)\n",
      "Loss is below 0.009185, reducing mutation range to 0.054000(p) and 0.027000(o)\n",
      "Loss is below 0.000865, reducing mutation range to 0.016200(p) and 0.008100(o)\n",
      "Loss is below 0.000079, reducing mutation range to 0.004860(p) and 0.002430(o)\n",
      "Epoch 160: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 160: 0.000010, time: 14.34s, goodness: 0.02\n",
      "Trial 14: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.796695\n",
      "Final loss in epoch 200: 0.126083, time: 18.00s, goodness: 453.96\n",
      "Trial 15: Population initialized with method random (initializaiton range +/-1.0)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.2, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 1.041068\n",
      "Loss is below 0.104107, reducing mutation range to 0.180000(p) and 0.060000(o)\n",
      "Loss is below 0.010245, reducing mutation range to 0.054000(p) and 0.018000(o)\n",
      "Final loss in epoch 200: 0.001385, time: 17.94s, goodness: 4.97\n",
      "Trial 16: Population initialized with method random (initializaiton range +/-0.8999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.5, Par mut rate: 0.04, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.928411\n",
      "Loss is below 0.092841, reducing mutation range to 0.150000(p) and 0.150000(o)\n",
      "Loss is below 0.008815, reducing mutation range to 0.045000(p) and 0.045000(o)\n",
      "Loss is below 0.000816, reducing mutation range to 0.013500(p) and 0.013500(o)\n",
      "Loss is below 0.000081, reducing mutation range to 0.004050(p) and 0.004050(o)\n",
      "Epoch 147: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 147: 0.000010, time: 12.82s, goodness: 0.02\n",
      "Trial 17: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.3, Par mut rate: 0.04, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.783387\n",
      "Loss is below 0.078339, reducing mutation range to 0.180000(p) and 0.090000(o)\n",
      "Loss is below 0.007709, reducing mutation range to 0.054000(p) and 0.027000(o)\n",
      "Loss is below 0.000718, reducing mutation range to 0.016200(p) and 0.008100(o)\n",
      "Loss is below 0.000067, reducing mutation range to 0.004860(p) and 0.002430(o)\n",
      "Epoch 118: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 118: 0.000009, time: 11.58s, goodness: 0.01\n",
      "Trial 18: Population initialized with method random (initializaiton range +/-1.0)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 1.068534\n",
      "Loss is below 0.106853, reducing mutation range to 0.150000(p) and 0.120000(o)\n",
      "Loss is below 0.010556, reducing mutation range to 0.045000(p) and 0.036000(o)\n",
      "Loss is below 0.001047, reducing mutation range to 0.013500(p) and 0.010800(o)\n",
      "Loss is below 0.000104, reducing mutation range to 0.004050(p) and 0.003240(o)\n",
      "Epoch 128: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 128: 0.000010, time: 10.86s, goodness: 0.01\n",
      "Trial 19: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.04, Cross method: one_point, Cross size: 100, Off mut range: 0.6, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.825884\n",
      "Final loss in epoch 200: 0.125871, time: 19.18s, goodness: 482.79\n",
      "Trial 20: Population initialized with method random (initializaiton range +/-0.8999999999999999)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.943016\n",
      "Loss is below 0.094302, reducing mutation range to 0.150000(p) and 0.150000(o)\n",
      "Loss is below 0.008817, reducing mutation range to 0.045000(p) and 0.045000(o)\n",
      "Loss is below 0.000865, reducing mutation range to 0.013500(p) and 0.013500(o)\n",
      "Loss is below 0.000074, reducing mutation range to 0.004050(p) and 0.004050(o)\n",
      "Final loss in epoch 200: 0.000011, time: 17.41s, goodness: 0.04\n",
      "Trial 21: Population initialized with method random (initializaiton range +/-1.0)\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.3, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 1.040145\n",
      "Final loss in epoch 200: 0.125466, time: 17.91s, goodness: 449.46\n",
      "Trial 22: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.741485\n",
      "Loss is below 0.074149, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.007152, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000701, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000063, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 115: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 115: 0.000009, time: 10.13s, goodness: 0.01\n",
      "Trial 23: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.764492\n",
      "Loss is below 0.076449, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007288, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000683, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000063, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 106: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 106: 0.000009, time: 9.39s, goodness: 0.01\n",
      "Trial 24: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.777377\n",
      "Final loss in epoch 200: 0.125892, time: 17.42s, goodness: 438.66\n",
      "Trial 25: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.718300\n",
      "Loss is below 0.071830, reducing mutation range to 0.200000(p) and 0.160000(o)\n",
      "Loss is below 0.006965, reducing mutation range to 0.080000(p) and 0.064000(o)\n",
      "Loss is below 0.000655, reducing mutation range to 0.032000(p) and 0.025600(o)\n",
      "Loss is below 0.000063, reducing mutation range to 0.012800(p) and 0.010240(o)\n",
      "Epoch 160: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 160: 0.000009, time: 14.00s, goodness: 0.02\n",
      "Trial 26: Population initialized with method random (initializaiton range +/-0.7999999999999999)\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.04, Cross method: one_point, Cross size: 100, Off mut range: 0.5, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.3\n",
      "Starting training with random seed 13. Initiation loss: 0.794638\n",
      "Final loss in epoch 200: 0.127083, time: 18.78s, goodness: 477.22\n",
      "Trial 27: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.733141\n",
      "Loss is below 0.073314, reducing mutation range to 0.200000(p) and 0.160000(o)\n",
      "Loss is below 0.006812, reducing mutation range to 0.080000(p) and 0.064000(o)\n",
      "Loss is below 0.000618, reducing mutation range to 0.032000(p) and 0.025600(o)\n",
      "Loss is below 0.000049, reducing mutation range to 0.012800(p) and 0.010240(o)\n",
      "Epoch 90: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 90: 0.000009, time: 7.46s, goodness: 0.01\n",
      "Trial 28: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.733751\n",
      "Loss is below 0.073375, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.007236, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000706, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000064, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 94: Loss is below 1e-05: 0.000007, stopping training\n",
      "Final loss in epoch 94: 0.000007, time: 8.27s, goodness: 0.01\n",
      "Trial 29: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.736898\n",
      "Final loss in epoch 200: 0.126025, time: 17.95s, goodness: 452.47\n",
      "Trial 30: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.3, Par mut rate: 0.04, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.04, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.759932\n",
      "Loss is below 0.075993, reducing mutation range to 0.200000(p) and 0.120000(o)\n",
      "Loss is below 0.007570, reducing mutation range to 0.080000(p) and 0.048000(o)\n",
      "Loss is below 0.000753, reducing mutation range to 0.032000(p) and 0.019200(o)\n",
      "Loss is below 0.000075, reducing mutation range to 0.012800(p) and 0.007680(o)\n",
      "Epoch 116: Loss is below 1e-05: 0.000007, stopping training\n",
      "Final loss in epoch 116: 0.000007, time: 11.35s, goodness: 0.01\n",
      "Trial 31: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.754135\n",
      "Loss is below 0.075413, reducing mutation range to 0.200000(p) and 0.160000(o)\n",
      "Loss is below 0.007294, reducing mutation range to 0.080000(p) and 0.064000(o)\n",
      "Loss is below 0.000715, reducing mutation range to 0.032000(p) and 0.025600(o)\n",
      "Loss is below 0.000071, reducing mutation range to 0.012800(p) and 0.010240(o)\n",
      "Final loss in epoch 200: 0.000065, time: 17.40s, goodness: 0.22\n",
      "Trial 32: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.743529\n",
      "Loss is below 0.074353, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007221, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000679, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000056, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 76: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 76: 0.000009, time: 6.69s, goodness: 0.00\n",
      "Trial 33: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.749986\n",
      "Loss is below 0.074999, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.007167, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000665, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000065, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 112: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 112: 0.000009, time: 9.81s, goodness: 0.01\n",
      "Trial 34: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.754237\n",
      "Final loss in epoch 200: 0.126469, time: 17.34s, goodness: 438.70\n",
      "Trial 35: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.724909\n",
      "Loss is below 0.072491, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.007074, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000698, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000064, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 129: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 129: 0.000009, time: 11.24s, goodness: 0.01\n",
      "Trial 36: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.5, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.741503\n",
      "Loss is below 0.074150, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007156, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000668, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000060, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 133: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 133: 0.000010, time: 11.65s, goodness: 0.01\n",
      "Trial 37: Population initialized with method he\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.5, Par mut range: 0.4, Par mut rate: 0.03, Cross method: one_point, Cross size: 150, Off mut range: 0.6, Off mut rate: 0.03, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.741489\n",
      "Loss is below 0.074149, reducing mutation range to 0.240000(p) and 0.160000(o)\n",
      "Loss is below 0.007025, reducing mutation range to 0.096000(p) and 0.064000(o)\n",
      "Loss is below 0.000675, reducing mutation range to 0.038400(p) and 0.025600(o)\n",
      "Loss is below 0.000061, reducing mutation range to 0.015360(p) and 0.010240(o)\n",
      "Epoch 119: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 119: 0.000009, time: 11.65s, goodness: 0.01\n",
      "Trial 38: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.715312\n",
      "Loss is below 0.071531, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.006147, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000602, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000042, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 71: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 71: 0.000009, time: 6.45s, goodness: 0.00\n",
      "Trial 39: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.731446\n",
      "Loss is below 0.073145, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.006246, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000569, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000052, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 135: Loss is below 1e-05: 0.000008, stopping training\n",
      "Final loss in epoch 135: 0.000008, time: 13.20s, goodness: 0.01\n",
      "Trial 40: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.6, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.751064\n",
      "Loss is below 0.075106, reducing mutation range to 0.240000(p) and 0.200000(o)\n",
      "Loss is below 0.007334, reducing mutation range to 0.096000(p) and 0.080000(o)\n",
      "Loss is below 0.000660, reducing mutation range to 0.038400(p) and 0.032000(o)\n",
      "Loss is below 0.000062, reducing mutation range to 0.015360(p) and 0.012800(o)\n",
      "Epoch 133: Loss is below 1e-05: 0.000008, stopping training\n",
      "Final loss in epoch 133: 0.000008, time: 11.94s, goodness: 0.01\n",
      "Trial 41: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.737516\n",
      "Loss is below 0.073752, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007068, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000689, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000068, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 77: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 77: 0.000009, time: 7.60s, goodness: 0.01\n",
      "Trial 42: Population initialized with method he\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.753008\n",
      "Loss is below 0.075301, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007149, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000655, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000065, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 78: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 78: 0.000010, time: 8.41s, goodness: 0.01\n",
      "Trial 43: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.754465\n",
      "Loss is below 0.075446, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.006832, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000644, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Final loss in epoch 200: 0.000096, time: 19.50s, goodness: 0.38\n",
      "Trial 44: Population initialized with method he\n",
      "Pop size: 1200, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.714526\n",
      "Loss is below 0.071453, reducing mutation range to 0.200000(p) and 0.200000(o)\n",
      "Loss is below 0.006768, reducing mutation range to 0.080000(p) and 0.080000(o)\n",
      "Loss is below 0.000583, reducing mutation range to 0.032000(p) and 0.032000(o)\n",
      "Loss is below 0.000052, reducing mutation range to 0.012800(p) and 0.012800(o)\n",
      "Epoch 94: Loss is below 1e-05: 0.000008, stopping training\n",
      "Final loss in epoch 94: 0.000008, time: 9.98s, goodness: 0.01\n",
      "Trial 45: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.720721\n",
      "Loss is below 0.072072, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007072, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000684, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000062, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 67: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 67: 0.000009, time: 6.08s, goodness: 0.00\n",
      "Trial 46: Population initialized with method he\n",
      "Pop size: 1100, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.738835\n",
      "Loss is below 0.073883, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.006841, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Final loss in epoch 200: 0.001928, time: 19.64s, goodness: 7.57\n",
      "Trial 47: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.732880\n",
      "Loss is below 0.073288, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007182, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000637, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000052, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 91: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 91: 0.000009, time: 8.22s, goodness: 0.01\n",
      "Trial 48: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.733506\n",
      "Loss is below 0.073351, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007263, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000653, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000064, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 81: Loss is below 1e-05: 0.000008, stopping training\n",
      "Final loss in epoch 81: 0.000008, time: 7.32s, goodness: 0.00\n",
      "Trial 49: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.6, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.5, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.732643\n",
      "Loss is below 0.073264, reducing mutation range to 0.200000(p) and 0.240000(o)\n",
      "Loss is below 0.007119, reducing mutation range to 0.080000(p) and 0.096000(o)\n",
      "Loss is below 0.000683, reducing mutation range to 0.032000(p) and 0.038400(o)\n",
      "Loss is below 0.000049, reducing mutation range to 0.012800(p) and 0.015360(o)\n",
      "Epoch 67: Loss is below 1e-05: 0.000010, stopping training\n",
      "Final loss in epoch 67: 0.000010, time: 6.08s, goodness: 0.00\n",
      "Trial 50: Population initialized with method he\n",
      "Pop size: 1000, Elite %: 0.1, Par sel method: roulette_wheel, Par sel %: 0.6, Par mut range: 0.5, Par mut rate: 0.05, Cross method: one_point, Cross size: 200, Off mut range: 0.6, Off mut rate: 0.05, Pop sel method: roulette_wheel, Mut ranges red fact: 0.4\n",
      "Starting training with random seed 13. Initiation loss: 0.726469\n",
      "Loss is below 0.072647, reducing mutation range to 0.240000(p) and 0.200000(o)\n",
      "Loss is below 0.006624, reducing mutation range to 0.096000(p) and 0.080000(o)\n",
      "Loss is below 0.000598, reducing mutation range to 0.038400(p) and 0.032000(o)\n",
      "Loss is below 0.000048, reducing mutation range to 0.015360(p) and 0.012800(o)\n",
      "Epoch 77: Loss is below 1e-05: 0.000009, stopping training\n",
      "Final loss in epoch 77: 0.000009, time: 6.97s, goodness: 0.00\n",
      "Finished study with 50 trials. Best (lowest) goodness: 0.00, best params: {'population_size': 1000, 'elitism_pct': 0.1, 'pop_init_method': 'random', 'pop_init_random_range': 0.8999999999999999, 'parent_selection_method': 'roulette_wheel', 'parent_selection_pct': 0.6, 'init_parent_mutation_range': 0.4, 'parent_mutation_rate': 0.04, 'crossover_method': 'one_point', 'crossover_num_offspring': 150, 'init_offspring_mutation_range': 0.6, 'pop_selection_method': 'roulette_wheel', 'mutation_ranges_reduction_factor': 0.3}\n",
      "Loaded existing results.csv\n",
      "Saved results to results.csv\n"
     ]
    }
   ],
   "source": [
    "# --- problem parameters\n",
    "MAX_EPOCHS = 200\n",
    "LAYERS = [2, 2, 1]\n",
    "PRINT_EVERY_N_EPOCHS = 100\n",
    "LOSS_TRESHOLD = 1 * 10**-5\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "trial_results = []\n",
    "def objective(trial):\n",
    "    # --- tunable hyperparameters\n",
    "    # POPULATION_SIZE = 1000\n",
    "    # ELITISM_PCT = 0.1\n",
    "    # POP_INIT_METHOD = 'random' # 'random' or 'he\n",
    "    # POP_INIT_RANDOM_RANGE = .5\n",
    "    # PARENT_SELECTION_METHOD = 'roulette_wheel' # 'roulette_wheel' or 'exp_rank'\n",
    "    # PARENT_SELECTION_PCT = 0.6\n",
    "    # PARENT_MUTATION_RANGE = 0.5\n",
    "    # PARENT_MUTATION_RATE = 0.001\n",
    "    # CROSSOVER_METHOD = 'one_point' # 'one_point' or 'mean'\n",
    "    # CROSSOVER_NUM_OFFSPRING = 1000\n",
    "    # OFFSPRING_MUTATION_RANGE = .5\n",
    "    # OFFSPRING_MUTATION_RATE = 0.01\n",
    "    # POP_SELECTION_METHOD = 'roulette_wheel' # 'roulette_wheel' or 'exp_rank'\n",
    "    # MUTATION_RANGES_REDUCTION_FACTOR = 0.3\n",
    "    POPULATION_SIZE = trial.suggest_int('population_size', 1000, 1200, step=100)\n",
    "    ELITISM_PCT = trial.suggest_float('elitism_pct', 0.1, 0.1, step=0.1)\n",
    "    POP_INIT_METHOD = trial.suggest_categorical('pop_init_method', ['random', 'he'])\n",
    "    POP_INIT_RANDOM_RANGE = trial.suggest_float('pop_init_random_range', 0.7, 1.1, step=0.1)\n",
    "    PARENT_SELECTION_METHOD = trial.suggest_categorical('parent_selection_method', ['roulette_wheel']) # no: 'exp_rank'\n",
    "    PARENT_SELECTION_PCT = trial.suggest_float('parent_selection_pct', 0.5, 0.6, step=0.1)\n",
    "    INIT_PARENT_MUTATION_RANGE = trial.suggest_float('init_parent_mutation_range', 0.2, 0.6, step=0.1)\n",
    "    PARENT_MUTATION_RATE = trial.suggest_categorical('parent_mutation_rate', [0.03, 0.04, 0.05])\n",
    "    CROSSOVER_METHOD = trial.suggest_categorical('crossover_method', ['one_point']) # no: 'mean'\n",
    "    CROSSOVER_NUM_OFFSPRING = trial.suggest_categorical('crossover_num_offspring', [100, 150, 200])\n",
    "    INIT_OFFSPRING_MUTATION_RANGE = trial.suggest_float('init_offspring_mutation_range', 0.5, 0.6, step=0.1)\n",
    "    OFFSPRING_MUTATION_RATE = trial.suggest_categorical('parent_mutation_rate', [0.03, 0.04, 0.05])\n",
    "    POP_SELECTION_METHOD = trial.suggest_categorical('pop_selection_method', ['roulette_wheel']) # no: 'exp_rank'\n",
    "    MUTATION_RANGES_REDUCTION_FACTOR = trial.suggest_float('mutation_ranges_reduction_factor', 0.3, 0.4, step=0.1)\n",
    "\n",
    "    # --- initialization\n",
    "    starttime = datetime.datetime.now()\n",
    "    model = ANN(layers=LAYERS, activation_fn=nn.Tanh)\n",
    "    # device = determine_device()\n",
    "    # X = X.to(device)\n",
    "    # Y = Y.to(device)\n",
    "    # model = model.to(device)\n",
    "    if POP_INIT_METHOD == 'random':\n",
    "        population = get_population(model, POPULATION_SIZE, POP_INIT_RANDOM_RANGE)\n",
    "    elif POP_INIT_METHOD == 'he':\n",
    "        population = get_population_he(model, POPULATION_SIZE)\n",
    "    print(f'Trial {trial.number + 1}: Population initialized with method {POP_INIT_METHOD}{f\" (initializaiton range +/-{POP_INIT_RANDOM_RANGE})\" if POP_INIT_METHOD == \"random\" else \"\"}')\n",
    "    print(f'Pop size: {POPULATION_SIZE}, '\n",
    "      f'Elite %: {ELITISM_PCT:.1f}, '\n",
    "      f'Par sel method: {PARENT_SELECTION_METHOD}, '\n",
    "      f'Par sel %: {PARENT_SELECTION_PCT:.1f}, '\n",
    "      f'Par mut range: {INIT_PARENT_MUTATION_RANGE:.1f}, '\n",
    "      f'Par mut rate: {PARENT_MUTATION_RATE}, '\n",
    "      f'Cross method: {CROSSOVER_METHOD}, '\n",
    "      f'Cross size: {CROSSOVER_NUM_OFFSPRING}, '\n",
    "      f'Off mut range: {INIT_OFFSPRING_MUTATION_RANGE:.1f}, '\n",
    "      f'Off mut rate: {OFFSPRING_MUTATION_RATE}, '\n",
    "      f'Pop sel method: {POP_SELECTION_METHOD}, '\n",
    "      f'Mut ranges red fact: {MUTATION_RANGES_REDUCTION_FACTOR:.1f}')\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # --- training\n",
    "    all_losses = []\n",
    "    losses, ranks = get_fitness(population, model=model, loss_fn=loss_fn, X=X, Y=Y)\n",
    "    DEBUG and draw_pt_fc_layers(set_all_parameters_from_vector(model, population[ranks[0]]))\n",
    "    initial_loss = losses.mean().item()\n",
    "    all_losses.append(initial_loss)\n",
    "    print(f\"Starting training with random seed {RANDOM_SEED}. Initiation loss: {initial_loss:6f}\")\n",
    "    loss_tracker = initial_loss\n",
    "    parent_mutation_range_tracker = INIT_PARENT_MUTATION_RANGE\n",
    "    offspring_mutation_range_tracker = INIT_OFFSPRING_MUTATION_RANGE\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        assert population.shape[0] == POPULATION_SIZE, f\"Population size is {population.shape[0]} but should be {POPULATION_SIZE}\"\n",
    "        assert ranks.shape[0] == POPULATION_SIZE, f\"Ranks size is {ranks.shape[0]} but should be {POPULATION_SIZE}\"\n",
    "\n",
    "        if ELITISM_PCT > 0:\n",
    "            n_elites = int(ELITISM_PCT * POPULATION_SIZE)\n",
    "            elites = population[ranks][:n_elites]\n",
    "\n",
    "        if PARENT_SELECTION_METHOD == 'exp_rank':\n",
    "            parents = exp_rank_selection(population, PARENT_SELECTION_PCT, ranks)\n",
    "        elif PARENT_SELECTION_METHOD == 'roulette_wheel':\n",
    "            parents = roulette_wheel_selection(population, PARENT_SELECTION_PCT, ranks)\n",
    "\n",
    "        if CROSSOVER_METHOD == 'one_point':\n",
    "            offspring = one_point_cross(parents, CROSSOVER_NUM_OFFSPRING)\n",
    "        elif CROSSOVER_METHOD == 'mean':\n",
    "            offspring = mean_cross(parents, CROSSOVER_NUM_OFFSPRING)\n",
    "        \n",
    "        if PARENT_MUTATION_RATE > 0 and parent_mutation_range_tracker > 0:\n",
    "            parents = mutate_population(parents, PARENT_MUTATION_RATE, parent_mutation_range_tracker)\n",
    "        if OFFSPRING_MUTATION_RATE > 0 and offspring_mutation_range_tracker > 0:\n",
    "            offspring = mutate_population(offspring, OFFSPRING_MUTATION_RATE, offspring_mutation_range_tracker)\n",
    "        population = torch.cat([parents, offspring])\n",
    "        \n",
    "        losses, ranks = get_fitness(population, model=model, loss_fn=loss_fn, X=X, Y=Y)\n",
    "\n",
    "        percentage = (POPULATION_SIZE - n_elites) / population.shape[0] if ELITISM_PCT > 0 else POPULATION_SIZE / population.shape[0]\n",
    "        if POP_SELECTION_METHOD == 'roulette_wheel':\n",
    "            population = roulette_wheel_selection(population, percentage, ranks)\n",
    "        elif POP_SELECTION_METHOD == 'exp_rank':\n",
    "            population = exp_rank_selection(population, percentage, ranks)\n",
    "\n",
    "        if ELITISM_PCT > 0:\n",
    "            population = torch.cat([elites, population])\n",
    "\n",
    "        if population.shape[0] != POPULATION_SIZE:\n",
    "            population = torch.cat([population, parents[:POPULATION_SIZE - population.shape[0]]])\n",
    "        \n",
    "        losses, ranks = get_fitness(population, model=model, loss_fn=loss_fn, X=X, Y=Y)\n",
    "        mean_loss = losses.mean().item()\n",
    "        all_losses.append(mean_loss)\n",
    "\n",
    "        if DEBUG and (epoch + 1) % PRINT_EVERY_N_EPOCHS == 0:\n",
    "            print(f\"Epoch {epoch + 1} - Loss: {mean_loss:6f}\")\n",
    "            draw_pt_fc_layers(set_all_parameters_from_vector(model, population[ranks[0]]))\n",
    "\n",
    "        if mean_loss < loss_tracker / 10:\n",
    "            offspring_mutation_range_tracker *= MUTATION_RANGES_REDUCTION_FACTOR\n",
    "            parent_mutation_range_tracker *= MUTATION_RANGES_REDUCTION_FACTOR\n",
    "            print(f\"Loss is below {loss_tracker / 10:6f}, reducing mutation range to {offspring_mutation_range_tracker:6f}(p) and {parent_mutation_range_tracker:6f}(o)\")\n",
    "            loss_tracker = mean_loss\n",
    "        \n",
    "        if mean_loss < LOSS_TRESHOLD:\n",
    "            print(f\"Epoch {epoch + 1}: Loss is below {LOSS_TRESHOLD}: {mean_loss:6f}, stopping training\")\n",
    "            break\n",
    "\n",
    "    trial_time = (datetime.datetime.now() - starttime).total_seconds()\n",
    "    goodness = mean_loss * (epoch + 1) * trial_time\n",
    "\n",
    "    print(f\"Final loss in epoch {epoch + 1}: {mean_loss:6f}, time: {trial_time:.2f}s, goodness: {goodness:.2f}\")\n",
    "\n",
    "    trial_results.append({\n",
    "        'initial_loss': initial_loss,\n",
    "        'final_loss': mean_loss,\n",
    "        'epochs': epoch + 1,\n",
    "        'max_epochs': MAX_EPOCHS,\n",
    "        'trial_time_s': trial_time,\n",
    "        'goodness': goodness,\n",
    "        'population_size': POPULATION_SIZE,\n",
    "        'elitism_pct': ELITISM_PCT,\n",
    "        'pop_init_method': POP_INIT_METHOD,\n",
    "        'pop_init_random_range': POP_INIT_RANDOM_RANGE,\n",
    "        'parent_selection_method': PARENT_SELECTION_METHOD,\n",
    "        'parent_selection_pct': PARENT_SELECTION_PCT,\n",
    "        'init_parent_mutation_range': INIT_PARENT_MUTATION_RANGE,\n",
    "        'parent_mutation_range_tracker': parent_mutation_range_tracker,\n",
    "        'parent_mutation_rate': PARENT_MUTATION_RATE,\n",
    "        'crossover_method': CROSSOVER_METHOD,\n",
    "        'crossover_num_offspring': CROSSOVER_NUM_OFFSPRING,\n",
    "        'init_offspring_mutation_range': INIT_OFFSPRING_MUTATION_RANGE,\n",
    "        'offspring_mutation_range_tracker': offspring_mutation_range_tracker,\n",
    "        'offspring_mutation_rate': OFFSPRING_MUTATION_RATE,\n",
    "        'pop_selection_method': POP_SELECTION_METHOD,\n",
    "        'mutation_ranges_reduction_factor': MUTATION_RANGES_REDUCTION_FACTOR,\n",
    "        'layers': LAYERS,\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'all_losses': all_losses,\n",
    "    })\n",
    "    \n",
    "    return goodness\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f'Finished study with {len(study.trials)} trials. Best (lowest) goodness: {study.best_value:.2f}, best params: {study.best_params}')\n",
    "\n",
    "df = pd.DataFrame(trial_results)\n",
    "try:\n",
    "    df_existing = pd.read_csv('results.csv')\n",
    "    print('Loaded existing results.csv')\n",
    "    df = pd.concat([df_existing, df])\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "df = df.sort_values('goodness', ascending=True)\n",
    "df.to_csv('results.csv', index=False)\n",
    "print('Saved results to results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9.22975959838368e-06, 64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "best_trial_values = trial_results[best_trial.number]\n",
    "plot_losses(best_trial_values['all_losses'])\n",
    "best_trial_values['final_loss'], best_trial_values['epochs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.2574\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"821pt\" height=\"188pt\" viewBox=\"0.00 0.00 820.73 188.32\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184.32)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184.32 816.73,-184.32 816.73,4 -4,4\"/>\n",
       "<!-- input.0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.53\" cy=\"-123.66\" rx=\"37.53\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.53\" y=\"-118.61\" font-family=\"Times,serif\" font-size=\"14.00\">Input 0</text>\n",
       "</g>\n",
       "<!-- layer.0.node.0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>layer.0.node.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"306.77\" cy=\"-139.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-151.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0, Node 0</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-134.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 0 0: 0.0816</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-118.11\" font-family=\"Times,serif\" font-size=\"14.00\">Tanh activation</text>\n",
       "</g>\n",
       "<!-- input.0&#45;&gt;layer.0.node.0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input.0-&gt;layer.0.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.6,-127.17C80.75,-127.71 87.09,-128.23 93.07,-128.66 135.03,-131.67 181.7,-134.17 220.61,-136.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.23,-139.52 230.38,-136.49 220.56,-132.52 220.23,-139.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-137.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 0 0: 0.1048</text>\n",
       "</g>\n",
       "<!-- layer.0.node.1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>layer.0.node.1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"306.77\" cy=\"-40.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-52.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0, Node 1</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-35.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 0 1: 0.1389</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-19.11\" font-family=\"Times,serif\" font-size=\"14.00\">Tanh activation</text>\n",
       "</g>\n",
       "<!-- input.0&#45;&gt;layer.0.node.1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>input.0-&gt;layer.0.node.1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.8,-114.09C77.38,-111.97 85.47,-109.84 93.07,-108.16 146.13,-96.37 162.22,-105.79 213.82,-88.66 224.33,-85.17 235.09,-80.59 245.39,-75.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.76,-78.86 254.14,-71.27 243.63,-72.6 246.76,-78.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-110.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 1 0: 0.2028</text>\n",
       "</g>\n",
       "<!-- input.1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input.1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.53\" cy=\"-56.66\" rx=\"37.53\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.53\" y=\"-51.61\" font-family=\"Times,serif\" font-size=\"14.00\">Input 1</text>\n",
       "</g>\n",
       "<!-- input.1&#45;&gt;layer.0.node.0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>input.1-&gt;layer.0.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.68,-52.76C111.52,-50.36 169.39,-51.05 213.82,-72.16 224.18,-77.08 222.98,-83.34 231.82,-90.66 236.75,-94.75 242.04,-98.81 247.43,-102.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.15,-105.41 255.33,-108.33 249.19,-99.69 245.15,-105.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-74.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 0 1: 0.3096</text>\n",
       "</g>\n",
       "<!-- input.1&#45;&gt;layer.0.node.1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>input.1-&gt;layer.0.node.1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.03,-43.01C72.16,-38.63 82.82,-34.36 93.07,-32.16 135.42,-23.08 183.58,-24.1 223.35,-27.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.78,-31.33 233.09,-28.87 223.5,-24.37 222.78,-31.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-34.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 1 1: -0.4698</text>\n",
       "</g>\n",
       "<!-- layer.1.node.0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>layer.1.node.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"613.43\" cy=\"-89.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-101.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1, Node 0</text>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-84.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 1 0: 0.5310</text>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-68.11\" font-family=\"Times,serif\" font-size=\"14.00\">No activation</text>\n",
       "</g>\n",
       "<!-- layer.0.node.0&#45;&gt;layer.1.node.0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>layer.0.node.0-&gt;layer.1.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.81,-128C424.06,-120.57 482.85,-110.92 530.13,-103.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"530.47,-106.66 539.78,-101.58 529.34,-99.75 530.47,-106.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"460.1\" y=\"-125.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 1 0 0: -0.1070</text>\n",
       "</g>\n",
       "<!-- layer.0.node.1&#45;&gt;layer.1.node.0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>layer.0.node.1-&gt;layer.1.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M379.2,-52.15C424.38,-59.41 482.94,-68.83 530.08,-76.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.26,-79.83 539.69,-77.96 530.37,-72.92 529.26,-79.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"460.1\" y=\"-76.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 1 0 1: -0.3753</text>\n",
       "</g>\n",
       "<!-- output.0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>output.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"769.05\" cy=\"-89.66\" rx=\"43.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"769.05\" y=\"-84.61\" font-family=\"Times,serif\" font-size=\"14.00\">Output 0</text>\n",
       "</g>\n",
       "<!-- layer.1.node.0&#45;&gt;output.0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>layer.1.node.0-&gt;output.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M688.54,-89.66C697.09,-89.66 705.69,-89.66 713.91,-89.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"713.71,-93.16 723.71,-89.66 713.71,-86.16 713.71,-93.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping on epoch 727 with loss 0.0000, because loss is below the treshold\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"821pt\" height=\"188pt\" viewBox=\"0.00 0.00 820.73 188.32\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184.32)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184.32 816.73,-184.32 816.73,4 -4,4\"/>\n",
       "<!-- input.0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.53\" cy=\"-123.66\" rx=\"37.53\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.53\" y=\"-118.61\" font-family=\"Times,serif\" font-size=\"14.00\">Input 0</text>\n",
       "</g>\n",
       "<!-- layer.0.node.0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>layer.0.node.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"306.77\" cy=\"-139.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-151.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0, Node 0</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-134.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 0 0: 0.6124</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-118.11\" font-family=\"Times,serif\" font-size=\"14.00\">Tanh activation</text>\n",
       "</g>\n",
       "<!-- input.0&#45;&gt;layer.0.node.0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input.0-&gt;layer.0.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.6,-127.17C80.75,-127.71 87.09,-128.23 93.07,-128.66 135.03,-131.67 181.7,-134.17 220.61,-136.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.23,-139.52 230.38,-136.49 220.56,-132.52 220.23,-139.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-137.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 0 0: -1.1888</text>\n",
       "</g>\n",
       "<!-- layer.0.node.1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>layer.0.node.1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"306.77\" cy=\"-40.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-52.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0, Node 1</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-35.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 0 1: 0.8338</text>\n",
       "<text text-anchor=\"middle\" x=\"306.77\" y=\"-19.11\" font-family=\"Times,serif\" font-size=\"14.00\">Tanh activation</text>\n",
       "</g>\n",
       "<!-- input.0&#45;&gt;layer.0.node.1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>input.0-&gt;layer.0.node.1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.8,-114.09C77.38,-111.97 85.47,-109.84 93.07,-108.16 146.13,-96.37 162.22,-105.79 213.82,-88.66 224.33,-85.17 235.09,-80.59 245.39,-75.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.76,-78.86 254.14,-71.27 243.63,-72.6 246.76,-78.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-110.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 1 0: 1.3789</text>\n",
       "</g>\n",
       "<!-- input.1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input.1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.53\" cy=\"-56.66\" rx=\"37.53\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.53\" y=\"-51.61\" font-family=\"Times,serif\" font-size=\"14.00\">Input 1</text>\n",
       "</g>\n",
       "<!-- input.1&#45;&gt;layer.0.node.0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>input.1-&gt;layer.0.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.68,-52.76C111.52,-50.36 169.39,-51.05 213.82,-72.16 224.18,-77.08 222.98,-83.34 231.82,-90.66 236.75,-94.75 242.04,-98.81 247.43,-102.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.15,-105.41 255.33,-108.33 249.19,-99.69 245.15,-105.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-74.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 0 1: 1.2194</text>\n",
       "</g>\n",
       "<!-- input.1&#45;&gt;layer.0.node.1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>input.1-&gt;layer.0.node.1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.03,-43.01C72.16,-38.63 82.82,-34.36 93.07,-32.16 135.42,-23.08 183.58,-24.1 223.35,-27.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.78,-31.33 233.09,-28.87 223.5,-24.37 222.78,-31.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.44\" y=\"-34.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 0 1 1: -1.4163</text>\n",
       "</g>\n",
       "<!-- layer.1.node.0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>layer.1.node.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"613.43\" cy=\"-89.66\" rx=\"74.95\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-101.11\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1, Node 0</text>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-84.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 1 0: 1.5535</text>\n",
       "<text text-anchor=\"middle\" x=\"613.43\" y=\"-68.11\" font-family=\"Times,serif\" font-size=\"14.00\">No activation</text>\n",
       "</g>\n",
       "<!-- layer.0.node.0&#45;&gt;layer.1.node.0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>layer.0.node.0-&gt;layer.1.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.81,-128C424.06,-120.57 482.85,-110.92 530.13,-103.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"530.47,-106.66 539.78,-101.58 529.34,-99.75 530.47,-106.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"460.1\" y=\"-125.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 1 0 0: -1.2764</text>\n",
       "</g>\n",
       "<!-- layer.0.node.1&#45;&gt;layer.1.node.0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>layer.0.node.1-&gt;layer.1.node.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M379.2,-52.15C424.38,-59.41 482.94,-68.83 530.08,-76.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.26,-79.83 539.69,-77.96 530.37,-72.92 529.26,-79.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"460.1\" y=\"-76.86\" font-family=\"Times,serif\" font-size=\"14.00\">Weight 1 0 1: -1.2506</text>\n",
       "</g>\n",
       "<!-- output.0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>output.0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"769.05\" cy=\"-89.66\" rx=\"43.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"769.05\" y=\"-84.61\" font-family=\"Times,serif\" font-size=\"14.00\">Output 0</text>\n",
       "</g>\n",
       "<!-- layer.1.node.0&#45;&gt;output.0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>layer.1.node.0-&gt;output.0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M688.54,-89.66C697.09,-89.66 705.69,-89.66 713.91,-89.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"713.71,-93.16 723.71,-89.66 713.71,-86.16 713.71,-93.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(tensor([0., 0.])) => tensor([0.0033], grad_fn=<ViewBackward0>)\n",
      "model(tensor([0., 1.])) => tensor([0.9968], grad_fn=<ViewBackward0>)\n",
      "model(tensor([1., 0.])) => tensor([0.9963], grad_fn=<ViewBackward0>)\n",
      "model(tensor([1., 1.])) => tensor([0.0020], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = ANN(layers=LAYERS, requires_grad=True, activation_fn=nn.Tanh)\n",
    "MAX_EPOCHS = 10000\n",
    "LOSS_TRESHOLD = 1 * 10**-5\n",
    "print_every_n_epochs = 1000\n",
    "loss_fn = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.9, weight_decay=0.0001) # 75 epochs\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.01) # 60 epochs\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr = 0.017, eps=1e-07, weight_decay=0.001) # 55 epochs\n",
    "all_losses = [] \n",
    "n_same_loss_early_stop = 100\n",
    "\n",
    "for epoch in range(MAX_EPOCHS): \n",
    "\n",
    "    y_hat = model(X)\n",
    "\n",
    "    loss = loss_fn(y_hat, Y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    all_losses.append(loss.detach().numpy())\n",
    "\n",
    "    if epoch % print_every_n_epochs == 0:\n",
    "        print(f'Epoch {epoch} Loss: {loss:.4f}')\n",
    "        draw_pt_fc_layers(model)\n",
    "    \n",
    "    last_n_same = len(all_losses) > n_same_loss_early_stop and len(set(np.array(all_losses[-n_same_loss_early_stop:]).tolist())) == 1\n",
    "    if loss < LOSS_TRESHOLD or last_n_same:\n",
    "        print(f'Early stopping on epoch {epoch} with loss {loss:.4f}, because {\"loss is below the treshold\" if loss < LOSS_TRESHOLD else f\"last {n_same_loss_early_stop} losses are the same\"}')\n",
    "        break\n",
    "\n",
    "draw_pt_fc_layers(model)\n",
    "for x in X:\n",
    "    print(f\"model({x}) => {model(x)}\")\n",
    "\n",
    "assert loss < LOSS_TRESHOLD, f\"Loss {loss} is not below the treshold {LOSS_TRESHOLD}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
